{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first class  using the lower api of tensorflow. It should be improved with drop out regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network:\n",
    "    def __init__(self, layers,  epochs=1200,  mini_batch=2000, learning_rate=0.01 ):\n",
    "        self.layers = layers\n",
    "        self.epochs = epochs\n",
    "        self.mini_batch = mini_batch \n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def create_weights(self, layer,tipe= \"fit\"):\n",
    "        if  tipe==\"fit\":\n",
    "            \n",
    "            return np.random.randn(self.layers_total[layer], self.layers_total[layer-1])\n",
    "                               \n",
    "        elif tipe== \"predict\":\n",
    "            return self.weigths[layer-1]\n",
    "  \n",
    "\n",
    "    def create_bias(self, layer, tipe= \"fit\"):\n",
    "        if  tipe==\"fit\":\n",
    "            \n",
    "            return np.zeros((self.layers_total[layer], 1))\n",
    "                               \n",
    "        elif tipe== \"predict\":\n",
    "            return self.bias[layer-1]\n",
    "        \n",
    "    def forward(self, tipe=\"fit\"):\n",
    "        \"\"\"Create the graph\"\"\"\n",
    "        layers = self.layers_total\n",
    "  \n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.X_placeholder = tf.placeholder(dtype=tf.float32, name=\"x_placeholder\")\n",
    "        self.y_placeholder = tf.placeholder(dtype=tf.int32, name=\"y_placeholder\")\n",
    "        \n",
    "        self.y_zeros = tf.one_hot(self.y_placeholder, self.n_categories,  dtype=tf.int32 )\n",
    "        \n",
    "        #y_zeros = np.zeros(( n ,  n_categories))\n",
    "        #for j in range(n):\n",
    "         #   y_zeros[j, int(y[j])] = 1\n",
    "        self.weigths_graph = []\n",
    "        self.bias_graph  = []\n",
    "        self.z_graph = []\n",
    "        self.a_graph =  []\n",
    "        \n",
    "        self.a_graph.append(self.X_placeholder)\n",
    "        \n",
    "        for l  in  range(1,len(layers)):\n",
    "            self.weigths_graph.append(tf.Variable(self.create_weights(l, tipe) ,\n",
    "                                                  dtype=tf.float32, name = \"weight_{}\".format(l)))\n",
    "            self.bias_graph.append(tf.Variable(self.create_bias(l, tipe), \n",
    "                                               dtype=tf.float32,  name = \"bias_{}\".format(l)))\n",
    "        for  l in range(1,len(layers)):\n",
    "            self.z_graph.append(tf.add(tf.matmul(self.weigths_graph[l-1],self.a_graph[l-1]),\n",
    "                                                self.bias_graph[l-1]) )\n",
    "            \n",
    "            if l+1< len(layers):\n",
    "                self.a_graph.append(tf.nn.leaky_relu(self.z_graph[l-1]))\n",
    "            \n",
    "            elif tipe==\"predict\":\n",
    "                self.a_graph.append(tf.nn.softmax(self.z_graph[l-1], axis=0))\n",
    "        \n",
    "        if tipe== \"fit\":\n",
    "            self.cost =  tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(self.y_zeros, tf.transpose(self.z_graph[-1])))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "    \n",
    "   \n",
    "    def fit(self, X, y):\n",
    "            \n",
    "        self.number_minibatchs = int(np.ceil(float(X.shape[0]) / self.mini_batch))\n",
    "        \n",
    "        X = X.T\n",
    "        self.n_categories = len(np.unique(y))\n",
    "        m ,  n = X.shape\n",
    "        self.layers_total = [m] + self.layers + [self.n_categories]\n",
    "        self.forward(tipe=\"fit\")\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        self.a =  []\n",
    "        indices = np.arange(X.shape[1])\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            for e in  range(self.epochs):\n",
    "                np.random.shuffle(indices)\n",
    "                for mini in range(self.number_minibatchs):\n",
    "                    lower_limit = mini * self.mini_batch\n",
    "                    upper_limit = (mini+1) * self.mini_batch\n",
    "\n",
    "                  \n",
    "                    sess.run(self.opt, feed_dict={self.X_placeholder:X[:,indices[lower_limit:upper_limit]], \n",
    "                                             self.y_placeholder:y[indices[lower_limit:upper_limit]]})\n",
    "\n",
    "                \n",
    "                if e%100==0:\n",
    "                    temp1, temp2, temp3 = sess.run([self.cost,self.y_zeros, self.z_graph[-1]  ], \n",
    "                                                   feed_dict={self.X_placeholder:X,  self.y_placeholder:y})\n",
    "                    print \"costo es {}\".format(temp1)\n",
    "\n",
    "                    self.a.append(temp3)\n",
    "                    \n",
    "            self.weigths = [w.eval() for  w in self.weigths_graph]\n",
    "            self.bias = [b.eval() for  b in self.bias_graph] \n",
    "    \n",
    "    def predict(self,X):\n",
    "        X = X.T\n",
    "        self.forward(tipe=\"predict\")\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        with tf.Session()as sess:\n",
    "            sess.run(init)\n",
    "            prediccion = sess.run(self.a_graph[-1], feed_dict={self.X_placeholder:X})\n",
    "        return prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javemar/miniconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/javemar/miniconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((52500, 784), (52500,), (17500, 784), (17500,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "X_train , X_test,y_train, y_test = train_test_split(mnist.data, mnist.target)\n",
    "\n",
    "X_train.shape ,y_train.shape , X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/javemar/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "costo es 13255.8310547\n",
      "costo es 22.8697433472\n",
      "costo es 31.929933548\n",
      "costo es 1.75168693066\n",
      "costo es 0.620983064175\n",
      "costo es 0.590853154659\n",
      "costo es 0.70061892271\n",
      "costo es 0.317730754614\n",
      "costo es 0.38599383831\n",
      "costo es 0.280421286821\n",
      "costo es 0.281893312931\n",
      "costo es 0.224350377917\n",
      "costo es 0.701605379581\n",
      "costo es 0.252493679523\n",
      "costo es 0.188815623522\n",
      "costo es 0.129340276122\n",
      "costo es 0.0738714635372\n",
      "costo es 0.133665367961\n",
      "costo es 0.0824574232101\n",
      "costo es 0.0532941408455\n",
      "costo es 0.0532832406461\n",
      "costo es 0.027783587575\n",
      "costo es 0.042276404798\n",
      "costo es 0.0726992040873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El train score es 0.991504761905'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nn = neural_network([25 ,20,18,16,10],epochs=2400)\n",
    "test_nn.fit(X_train, y_train)\n",
    "\n",
    "prediccion = np.argmax(test_nn.predict(X_train),  axis=0)\n",
    "\"El train score es {}\".format((prediccion==y_train).sum() /float(y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El test score es 0.936342857143'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prediccion = np.argmax(test_nn.predict(X_test),  axis=0)\n",
    "\"El test score es {}\".format((prediccion==y_test).sum() /float(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
